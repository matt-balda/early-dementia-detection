{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xjWL6wjk0ox3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV,TimeSeriesSplit, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "from sklearn.metrics import recall_score, precision_score, accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, f1_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "from collections import Counter\n",
        "from scipy.stats import loguniform, uniform as stats_uniform\n",
        "\n",
        "# Scikit-learn e Imblearn\n",
        "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import make_scorer, f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "\n",
        "# Imblearn\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import TomekLinks\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHmP-0Gb1UyH",
        "outputId": "7dc5a874-7c60-41cb-9b02-a5aa7bc984c1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# carregando dataset\n",
        "train =pd.read_csv(\"/content/drive/MyDrive/MESTRADO/CMP Aprendizado de MaÌquina/TRABALHO/DADOS ESSE/train_data (1).csv\")\n",
        "val =pd.read_csv(\"/content/drive/MyDrive/MESTRADO/CMP Aprendizado de MaÌquina/TRABALHO/DADOS ESSE/val_data (1).csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/MESTRADO/CMP Aprendizado de MaÌquina/TRABALHO/DADOS ESSE/test_data (1).csv\")"
      ],
      "metadata": {
        "id": "QxQ_go9D1YD0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REGRESSAO LOGISTICA CROSS VALIDATION VANILA**"
      ],
      "metadata": {
        "id": "uKDsJiKL1kib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dividindo em treino e teste para treinamento do modelo\n",
        "X_train = train.drop(['patient_id','date','label'], axis=1)\n",
        "y_train = train['label']\n",
        "\n",
        "X_val = val.drop(['patient_id','date','label'], axis=1)\n",
        "y_val = val['label']\n",
        "\n",
        "X_test = test.drop(['patient_id','date','label'], axis=1)\n",
        "y_test = test['label']"
      ],
      "metadata": {
        "id": "_PuyMkYp12j6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score # NecessÃ¡rio para a avaliaÃ§Ã£o final\n",
        "\n",
        "# A funÃ§Ã£o assume que X_train, y_train, pipeline, outer_tscv, inner_tscv,\n",
        "# param_distributions, scoring, n_iter e RANDOM_STATE estÃ£o definidos no escopo global.\n",
        "\n",
        "def perform_nested_cv_corrected_accuracy(X_train, y_train, pipeline, inner_tscv, outer_tscv, param_distributions, scoring, n_iter, RANDOM_STATE):\n",
        "\n",
        "    # Listas para armazenar os resultados (mudanÃ§a de nome para refletir 'accuracy')\n",
        "    nested_scores_accuracy = []\n",
        "    nested_best_params = []\n",
        "    nested_best_scores_inner = []\n",
        "\n",
        "    # 1. Loop Externo\n",
        "    for i, (outer_train_index, outer_test_index) in enumerate(outer_tscv.split(X_train, y_train)):\n",
        "        print(f\"\\n--- Outer Split {i+1}/{outer_tscv.get_n_splits()} ---\")\n",
        "\n",
        "        # Split de dados (ORIGINAIS)\n",
        "        # Adicionei .copy() para boas prÃ¡ticas, embora .iloc funcione bem\n",
        "        X_train_outer, X_test_outer = X_train.iloc[outer_train_index].copy(), X_train.iloc[outer_test_index].copy()\n",
        "        y_train_outer, y_test_outer = y_train.iloc[outer_train_index].copy(), y_train.iloc[outer_test_index].copy()\n",
        "\n",
        "        print(f\"Outer Train Data Shape (Original): {X_train_outer.shape}\")\n",
        "        print(f\"Outer Test Data Shape (Original): {X_test_outer.shape}\")\n",
        "\n",
        "        # 2. Loop Interno (RandomizedSearchCV)\n",
        "        print(\"Starting inner Randomized Search (SMOTETomek in Pipeline)...\")\n",
        "\n",
        "        inner_search = RandomizedSearchCV(\n",
        "            estimator=pipeline, # Usa o ImbPipeline com SMOTETomek\n",
        "            param_distributions=param_distributions,\n",
        "            n_iter=n_iter,\n",
        "            cv=inner_tscv, # Validador interno\n",
        "            scoring=scoring,\n",
        "            refit='accuracy', # ðŸŽ¯ CORREÃ‡ÃƒO 1: O modelo serÃ¡ reajustado com base na 'accuracy'\n",
        "            random_state=RANDOM_STATE,\n",
        "            n_jobs=-1,\n",
        "            return_train_score=True,\n",
        "            error_score=0.0\n",
        "        )\n",
        "\n",
        "        # FIT nos dados de treino externos ORIGINAIS (ImbPipeline faz a amostragem internamente)\n",
        "        inner_search.fit(X_train_outer, y_train_outer)\n",
        "\n",
        "        print(\"Inner Search completed.\")\n",
        "\n",
        "        # Armazenar os resultados internos (accuracy)\n",
        "        nested_best_params.append(inner_search.best_params_)\n",
        "        nested_best_scores_inner.append(inner_search.best_score_)\n",
        "        print(f\"Inner CV best params (refit='accuracy'): {inner_search.best_params_}\")\n",
        "        print(f\"Inner CV best accuracy score: {inner_search.best_score_}\") # Print corrigido\n",
        "\n",
        "        # 3. AvaliaÃ§Ã£o no Teste Externo (MÃ©trica final)\n",
        "        print(\"Evaluating best model on the outer test fold...\")\n",
        "        best_inner_model = inner_search.best_estimator_\n",
        "\n",
        "        # O modelo treinado jÃ¡ Ã© o ImbPipeline\n",
        "        y_pred_outer = best_inner_model.predict(X_test_outer)\n",
        "\n",
        "        # ðŸŽ¯ CORREÃ‡ÃƒO 2: Usamos accuracy_score como mÃ©trica de desempenho final\n",
        "        outer_accuracy_score = accuracy_score(y_test_outer, y_pred_outer)\n",
        "\n",
        "        nested_scores_accuracy.append(outer_accuracy_score)\n",
        "        print(f\"Outer fold Accuracy score: {outer_accuracy_score}\") # Print corrigido\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # 4. Resultados Finais\n",
        "    print(\"\\n--- Resultados Finais da ValidaÃ§Ã£o Cruzada Aninhada ---\")\n",
        "    print(f\"Nested CV Accuracy scores (por fold): {nested_scores_accuracy}\") # Print corrigido\n",
        "    print(f\"Mean Nested CV Accuracy score: {np.mean(nested_scores_accuracy)}\") # Print corrigido\n",
        "    print(f\"Standard deviation of Nested CV Accuracy scores: {np.std(nested_scores_accuracy)}\") # Print corrigido\n",
        "\n",
        "    # Retorno corrigido\n",
        "    return nested_scores_accuracy, nested_best_params, nested_best_scores_inner, np.std(nested_scores_accuracy)"
      ],
      "metadata": {
        "id": "EXrbGeknI0xF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X, y, set_name=\"set\"):\n",
        "    \"\"\"Avalia o modelo em um conjunto de dados e exibe mÃ©tricas.\"\"\"\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    # Verifica se o modelo tem predict_proba antes de chamar\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        y_proba = model.predict_proba(X)[:, 1]\n",
        "    else:\n",
        "        y_proba = None\n",
        "\n",
        "    acc = accuracy_score(y, y_pred)\n",
        "    # Define zero_division=0 para evitar avisos e garantir que o relatÃ³rio seja calculado\n",
        "    report = classification_report(y, y_pred, digits=4, zero_division=0)\n",
        "    cm = confusion_matrix(y, y_pred)\n",
        "\n",
        "    print(f\"\\n-------------------------------------------- AvaliaÃ§Ã£o no {set_name} -------------------------------------------\\n\")\n",
        "    print(\"Accuracy:\", acc)\n",
        "    print(\"\\nClassification report:\\n\", report)\n",
        "    print(\"Confusion matrix:\\n\", cm)\n",
        "\n",
        "    # Plota Matriz de ConfusÃ£o\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "    plt.title(f\"Matriz de ConfusÃ£o - {set_name}\")\n",
        "    plt.xlabel(\"Previsto\")\n",
        "    plt.ylabel(\"Verdadeiro\")\n",
        "    plt.show()\n",
        "\n",
        "    unique_classes = np.unique(y)\n",
        "    if len(unique_classes) == 2 and y_proba is not None:\n",
        "        auc = roc_auc_score(y, y_proba)\n",
        "        print(\"\\nROC AUC:\", auc)\n",
        "        fpr, tpr, thr = roc_curve(y, y_proba)\n",
        "\n",
        "        # Plota Curva ROC\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        plt.plot(fpr, tpr, label=f\"AUC = {auc:.4f}\")\n",
        "        plt.plot([0,1],[0,1],\"--\")\n",
        "        plt.xlabel(\"False Positive Rate\")\n",
        "        plt.ylabel(\"True Positive Rate\")\n",
        "        plt.title(f\"Curva ROC - {set_name}\")\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    return {\"accuracy\": acc, \"report_str\": report, \"confusion_matrix\": cm}\n"
      ],
      "metadata": {
        "id": "wopzuNztcKuI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PARÃ‚METROS GLOBAIS ---\n",
        "RANDOM_STATE = 42\n",
        "n_iter = 50\n",
        "n_splits_outer = 5 # Para o TimeSeriesSplit externo\n",
        "n_splits_inner = 5 # Para o TimeSeriesSplit interno\n",
        "\n",
        "# Definindo os validadores\n",
        "outer_tscv = TimeSeriesSplit(n_splits=n_splits_outer)\n",
        "inner_tscv = TimeSeriesSplit(n_splits=n_splits_inner)\n",
        "\n",
        "# --- DEFINIÃ‡ÃƒO DO PIPELINE COM SMOTETOMEK ---\n",
        "model_base = LogisticRegression(random_state=RANDOM_STATE, n_jobs=-1)\n",
        "\n",
        "smote_tomek_instance = SMOTETomek(\n",
        "    smote=SMOTE(random_state=RANDOM_STATE),\n",
        "    tomek=TomekLinks(n_jobs=-1), # Parallelismo para undersampling\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Pipeline CORRETO: SMOTETomek + Classificador (Usando ImbPipeline)\n",
        "pipeline = ImbPipeline(steps=[\n",
        "    ('smote_tomek', smote_tomek_instance), # Passo de amostragem\n",
        "    ('model', model_base)                  # Passo do modelo (LogisticRegression)\n",
        "])\n",
        "\n",
        "# --- METRICAS DE SCORING ---\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'precision': make_scorer(precision_score, zero_division=0),\n",
        "    'recall': make_scorer(recall_score, zero_division=0),\n",
        "    'f1': make_scorer(f1_score, zero_division=0), # MÃ©trica de refit\n",
        "    'roc_auc': make_scorer(roc_auc_score, zero_division=0)\n",
        "}\n",
        "\n",
        "# --- PARAM_DISTRIBUTIONS CORRIGIDO E OTIMIZADO ---\n",
        "param_distributions = [\n",
        "    # l1 penalty (Solver: liblinear)\n",
        "    {'model__penalty': ['l1'], 'model__solver': ['liblinear'], 'model__C': loguniform(0.0001, 100.0), 'model__max_iter': [10000]},\n",
        "\n",
        "    # elasticnet penalty (Solver: saga) - Cuidado: saga pode falhar, max_iter alto Ã© essencial\n",
        "    {'model__penalty': ['elasticnet'], 'model__solver': ['saga'], 'model__C': loguniform(0.0001, 100.0), 'model__l1_ratio': stats_uniform(0, 1), 'model__max_iter': [10000]},\n",
        "\n",
        "    # l2 penalty (Solvers: newton-cg, lbfgs, liblinear, sag, saga)\n",
        "    {'model__penalty': ['l2'], 'model__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'model__C': loguniform(0.0001, 100.0), 'model__max_iter': [10000]},\n",
        "\n",
        "    # None penalty (Solvers: newton-cg, lbfgs, sag, saga)\n",
        "    {'model__penalty': [None], 'model__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'], 'model__max_iter': [10000]},\n",
        "]\n"
      ],
      "metadata": {
        "id": "c-1gJ1jrTFkx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VALIDAÃ‡AO CRUZADA ANINHADA**"
      ],
      "metadata": {
        "id": "FmDKhvZg6-Xb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perform_nested_cv_corrected_accuracy(X_train, y_train, pipeline, inner_tscv, outer_tscv, param_distributions, scoring, n_iter, RANDOM_STATE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LooDsSy9UB18",
        "outputId": "864f0462-f992-4ed6-969c-ba830a8d86a1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Outer Split 1/5 ---\n",
            "Outer Train Data Shape (Original): (335, 36)\n",
            "Outer Test Data Shape (Original): (334, 36)\n",
            "Starting inner Randomized Search (SMOTETomek in Pipeline)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inner Search completed.\n",
            "Inner CV best params (refit='accuracy'): {'model__C': np.float64(0.0008632008168602544), 'model__max_iter': 10000, 'model__penalty': 'l1', 'model__solver': 'liblinear'}\n",
            "Inner CV best accuracy score: 0.9563636363636364\n",
            "Evaluating best model on the outer test fold...\n",
            "Outer fold Accuracy score: 0.8203592814371258\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Outer Split 2/5 ---\n",
            "Outer Train Data Shape (Original): (669, 36)\n",
            "Outer Test Data Shape (Original): (334, 36)\n",
            "Starting inner Randomized Search (SMOTETomek in Pipeline)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inner Search completed.\n",
            "Inner CV best params (refit='accuracy'): {'model__C': np.float64(0.0008632008168602544), 'model__max_iter': 10000, 'model__penalty': 'l1', 'model__solver': 'liblinear'}\n",
            "Inner CV best accuracy score: 0.872072072072072\n",
            "Evaluating best model on the outer test fold...\n",
            "Outer fold Accuracy score: 0.9700598802395209\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Outer Split 3/5 ---\n",
            "Outer Train Data Shape (Original): (1003, 36)\n",
            "Outer Test Data Shape (Original): (334, 36)\n",
            "Starting inner Randomized Search (SMOTETomek in Pipeline)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inner Search completed.\n",
            "Inner CV best params (refit='accuracy'): {'model__C': np.float64(0.0008632008168602544), 'model__max_iter': 10000, 'model__penalty': 'l1', 'model__solver': 'liblinear'}\n",
            "Inner CV best accuracy score: 0.904191616766467\n",
            "Evaluating best model on the outer test fold...\n",
            "Outer fold Accuracy score: 0.9401197604790419\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Outer Split 4/5 ---\n",
            "Outer Train Data Shape (Original): (1337, 36)\n",
            "Outer Test Data Shape (Original): (334, 36)\n",
            "Starting inner Randomized Search (SMOTETomek in Pipeline)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inner Search completed.\n",
            "Inner CV best params (refit='accuracy'): {'model__C': np.float64(0.0008632008168602544), 'model__max_iter': 10000, 'model__penalty': 'l1', 'model__solver': 'liblinear'}\n",
            "Inner CV best accuracy score: 0.9126126126126126\n",
            "Evaluating best model on the outer test fold...\n",
            "Outer fold Accuracy score: 0.907185628742515\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Outer Split 5/5 ---\n",
            "Outer Train Data Shape (Original): (1671, 36)\n",
            "Outer Test Data Shape (Original): (334, 36)\n",
            "Starting inner Randomized Search (SMOTETomek in Pipeline)...\n",
            "Inner Search completed.\n",
            "Inner CV best params (refit='accuracy'): {'model__C': np.float64(0.0008632008168602544), 'model__max_iter': 10000, 'model__penalty': 'l1', 'model__solver': 'liblinear'}\n",
            "Inner CV best accuracy score: 0.9093525179856113\n",
            "Evaluating best model on the outer test fold...\n",
            "Outer fold Accuracy score: 0.9520958083832335\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Resultados Finais da ValidaÃ§Ã£o Cruzada Aninhada ---\n",
            "Nested CV Accuracy scores (por fold): [0.8203592814371258, 0.9700598802395209, 0.9401197604790419, 0.907185628742515, 0.9520958083832335]\n",
            "Mean Nested CV Accuracy score: 0.9179640718562874\n",
            "Standard deviation of Nested CV Accuracy scores: 0.052939008635449904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.8203592814371258,\n",
              "  0.9700598802395209,\n",
              "  0.9401197604790419,\n",
              "  0.907185628742515,\n",
              "  0.9520958083832335],\n",
              " [{'model__C': np.float64(0.0008632008168602544),\n",
              "   'model__max_iter': 10000,\n",
              "   'model__penalty': 'l1',\n",
              "   'model__solver': 'liblinear'},\n",
              "  {'model__C': np.float64(0.0008632008168602544),\n",
              "   'model__max_iter': 10000,\n",
              "   'model__penalty': 'l1',\n",
              "   'model__solver': 'liblinear'},\n",
              "  {'model__C': np.float64(0.0008632008168602544),\n",
              "   'model__max_iter': 10000,\n",
              "   'model__penalty': 'l1',\n",
              "   'model__solver': 'liblinear'},\n",
              "  {'model__C': np.float64(0.0008632008168602544),\n",
              "   'model__max_iter': 10000,\n",
              "   'model__penalty': 'l1',\n",
              "   'model__solver': 'liblinear'},\n",
              "  {'model__C': np.float64(0.0008632008168602544),\n",
              "   'model__max_iter': 10000,\n",
              "   'model__penalty': 'l1',\n",
              "   'model__solver': 'liblinear'}],\n",
              " [np.float64(0.9563636363636364),\n",
              "  np.float64(0.872072072072072),\n",
              "  np.float64(0.904191616766467),\n",
              "  np.float64(0.9126126126126126),\n",
              "  np.float64(0.9093525179856113)],\n",
              " np.float64(0.052939008635449904))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}